# Batch-RL-Paper-Lists
Paper Collection for Batch RL with brief introductions.

Batch RL can be seen as an interesting specifc area in imitation learning yet it learn purely from demonstrations (batch data) and do not need to interact with the environment.

# Overview

TBA


## Try to imitate without interacting with environments

* <[Exponentially Weighted Imitation Learning for Batched Historical Data
](https://papers.nips.cc/paper/7866-exponentially-weighted-imitation-learning-for-batched-historical-data.pdf)> by Qing Wang, Jiechao Xiong, Lei Han, Peng Sun, Han Liu and Tong Zhang, NIPS 2018.

## General Batch RL

* <[Benchmarking Batch Deep Reinforcement Learning Algorithms](https://arxiv.org/abs/1910.01708)> by Fujimoto, Edoardo Conti, Mohammad Ghavamzadeh, Joelle Pineau, 2019.

* <[Truly Batch Apprenticeship Learning with Deep Successor Features](https://arxiv.org/pdf/1903.10077)>, Donghun Lee, Srivatsan Srinivasan and Finale Doshi-Velez, 2019.

* [BCQ]<[Off-Policy Deep Reinforcement Learning without Exploration](https://arxiv.org/abs/1812.02900)> by Scott Fujimoto, David Meger and Doina Precup, 2019.

* [BEAR] <[Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction](https://arxiv.org/1906.00949)> by Aviral Kumar, Justin Fu, George Tucker and Sergey Levine, NIPS 2019.

* <[Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog](https://arxiv.org/abs/1907.00456)> by Natasha Jaques et al. 2019.

* [AWR] <[Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning](https://arxiv.org/1910.00177)> by Xue Bin Peng,  Aviral Kumar,  Grace Zhang and Sergey Levine,  2019.

* <[Behavior Regularized Offline Reinforcement Learning](https://arxiv.org/abs/1911.11361)> by Yifan Wu, George Tucker, Ofir Nachum,  2019.

* [AlgaeDICE] <[AlgaeDICE: Policy Gradient from Arbitrary Experience](https://arxiv.org/abs/1912.02074)> by Ofir Nachum et al. 2019.

* [REM] <[An Optimistic Perspective on Offline Reinforcement Learning](https://arxiv.org/abs/1907.04543)> by Rishabh Agarwal, Dale Schuurmans and Mohammad Norouzi, ICML 2020.

* <[Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning](https://arxiv.org/2002.08396)> by Siegel et al. IClR 2020.

* <[Provably Good Batch Reinforcement Learning Without Great Exploration](https://arxiv.org/2007.08202)> by Yao Liu, Adith Swaminathan, Alekh Agarwal and Emma Brunskill, NIPS 2020.

* [MOReL] <[MOReL : Model-Based Offline Reinforcement Learning](https://arxiv.org/abs/2005.05951)> by Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli and Thorsten Joachims, NIPS 2020.

* [MOPO] <[MOPO: Model-based Offline Policy Optimization](https://arxiv.org/abs/2005.13239)> by Tianhe Yu et al. NIPS 2020.

* <[Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation](https://arxiv.org/abs/2006.13189)> by W, Aaron Sonabend et al. NIPS 2020.

* <[Multi-Task Batch Reinforcement Learning with Metric Learning](https://arxiv.org/abs/1909.11373)> by Jiachen Li et al. NIPS 2020.

* <[BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning](https://arxiv.org/abs/1910.12179)> by Xinyue Chen et al. NIPS 2020.

* <[Strictly Batch Imitation Learning by Energy-based Distribution Matching](https://arxiv.org/abs/2006.14154)> by Daniel Jarrett, Ioana Bica and Mihaela van der Schaar. NIPS 2020.






